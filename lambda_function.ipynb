{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de5e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#omgamganapathayenamaha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a292061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import cloudpickle\n",
    "\n",
    "print(\"Cold Start\")\n",
    "# grab environment variables\n",
    "endpoint_name = os.environ['ENDPOINT_NAME']\n",
    "client = boto3.client(service_name='sagemaker-runtime')\n",
    "\n",
    "class sparse_to_dense:\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n",
    "\n",
    "data_pipeline = None\n",
    "if os.path.exists('/tmp/data_pipeline_downloaded') and os.path.isfile('/tmp/data_pipeline_downloaded'):\n",
    "    print('Downloaded pipeline already present')\n",
    "    #with open('/tmp/data_pipeline_downloaded', 'rb') as fh:\n",
    "        #data_pipeline = pickle.load(fh)\n",
    "    data_pipeline = joblib.load('/tmp/data_pipeline_downloaded')\n",
    "else:\n",
    "    print('Downloaded pipeline is not present')\n",
    "    pipeln_bucket = 'ganesa-ml-sagemaker'\n",
    "    pipeln_object = 'binary_text_classification/data_pipeline/data_pipeline'\n",
    "    with open('/tmp/data_pipeline_downloaded', 'wb') as fw:\n",
    "        boto3.Session(region_name='us-east-1').resource('s3').Bucket(pipeln_bucket).Object(pipeln_object).download_fileobj(fw)\n",
    "    print('Downloaded pipeline from s3')\n",
    "    #with open('/tmp/data_pipeline_downloaded', 'rb') as fh:\n",
    "        #data_pipeline = pickle.load(fh)\n",
    "    data_pipeline = joblib.load('/tmp/data_pipeline_downloaded')\n",
    "\n",
    "def transform(data):\n",
    "    global data_pipeline\n",
    "    from __main__ import sparse_to_dense\n",
    "    print(\"In transform\")\n",
    "    try:\n",
    "        data_copy = json.loads(json.dumps(data))\n",
    "        return data_pipeline.transform(data_copy)\n",
    "    except Exception as err:\n",
    "        print('Error when transforming: {0},{1}'.format(data,err))\n",
    "        raise Exception('Error when transforming: {0},{1}'.format(data,err))\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(\"In lambda_handler\")\n",
    "    try:    \n",
    "        print(\"Received event: \" + json.dumps(event, indent=2))\n",
    "        \n",
    "        request = json.loads(json.dumps(event))\n",
    "        \n",
    "    \n",
    "        X_test = [instance['features'] for instance in request['instances']]\n",
    "        X_test = transform(X_test)\n",
    "        print(X_test)\n",
    "\n",
    "        result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body='\\n'.join([','.join([str(ite) for ite in item]) for item in X_test.tolist()]).encode('utf-8'),\n",
    "                       ContentType='text/csv')\n",
    "    \n",
    "        result = result['Body'].read().decode('utf-8')\n",
    "        print(result)\n",
    "        y_pred = [float(item) for item in result.split() if item != \"\"]\n",
    "        print(y_pred)\n",
    "    \n",
    "        # Splitting using regular expression as xgboost 1-2-2 is returning\n",
    "        # predicted values with inconsistent delimiters (comma, newline or both)\n",
    "\n",
    "        # pattern looks for one or more of non-numeric characters\n",
    "        #pattern = r'[^0-9.]+'\n",
    "        \n",
    "        # Apply inverse transformation to get the rental count\n",
    "        #result = re.split(pattern,result)\n",
    "        \n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'isBase64Encoded':False,\n",
    "            'body': json.dumps(y_pred)\n",
    "        }\n",
    "\n",
    "    except Exception as err:\n",
    "        return {\n",
    "            'statusCode': 400,\n",
    "            'isBase64Encoded':False,\n",
    "            'body': 'Call Failed {0}'.format(err)\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
